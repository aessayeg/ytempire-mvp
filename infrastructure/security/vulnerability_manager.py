#!/usr/bin/env python3
"""
Vulnerability Management System for YTEmpire
Implements automated scanning, patch management, and container security scanning
"""

import os
import sys
import json
import asyncio
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import aiohttp
import yaml
import docker
import psycopg2
from psycopg2.extras import RealDictCursor
import redis

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SeverityLevel(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class VulnerabilityType(Enum):
    """Types of vulnerabilities"""
    CVE = "cve"
    DEPENDENCY = "dependency"
    CONFIGURATION = "configuration"
    CODE = "code"
    CONTAINER = "container"
    INFRASTRUCTURE = "infrastructure"

class PatchStatus(Enum):
    """Patch management status"""
    AVAILABLE = "available"
    TESTING = "testing"
    APPROVED = "approved"
    APPLIED = "applied"
    FAILED = "failed"
    DEFERRED = "deferred"

@dataclass
class Vulnerability:
    """Vulnerability information"""
    id: str
    type: VulnerabilityType
    severity: SeverityLevel
    title: str
    description: str
    affected_component: str
    cve_id: Optional[str] = None
    cvss_score: Optional[float] = None
    patch_available: bool = False
    patch_version: Optional[str] = None
    discovered_at: datetime = field(default_factory=datetime.now)
    remediation: Optional[str] = None
    references: List[str] = field(default_factory=list)

@dataclass
class ScanResult:
    """Security scan result"""
    scan_id: str
    scan_type: str
    target: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    vulnerabilities: List[Vulnerability] = field(default_factory=list)
    summary: Dict[str, int] = field(default_factory=dict)
    status: str = "running"

@dataclass
class Patch:
    """Patch information"""
    patch_id: str
    vulnerability_id: str
    component: str
    current_version: str
    patch_version: str
    status: PatchStatus
    test_status: Optional[str] = None
    applied_at: Optional[datetime] = None
    rollback_available: bool = False

class VulnerabilityManager:
    """Comprehensive vulnerability management system"""
    
    def __init__(self):
        self.db_config = {
            'host': os.getenv('DATABASE_HOST', 'localhost'),
            'port': int(os.getenv('DATABASE_PORT', '5432')),
            'database': os.getenv('DATABASE_NAME', 'ytempire'),
            'user': os.getenv('DATABASE_USER', 'postgres'),
            'password': os.getenv('DATABASE_PASSWORD', 'password')
        }
        
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', '6379')),
            decode_responses=True
        )
        
        self.docker_client = None
        try:
            self.docker_client = docker.from_env()
        except:
            logger.warning("Docker client not available")
        
        self.scan_tools = {
            "trivy": "/usr/local/bin/trivy",
            "grype": "/usr/local/bin/grype",
            "snyk": "/usr/local/bin/snyk",
            "safety": "safety",
            "bandit": "bandit",
            "semgrep": "semgrep"
        }
        
    async def perform_complete_vulnerability_assessment(self) -> Dict[str, Any]:
        """Perform complete vulnerability assessment"""
        logger.info("Starting comprehensive vulnerability assessment")
        
        assessment_result = {
            "timestamp": datetime.now().isoformat(),
            "dependency_scanning": {},
            "container_scanning": {},
            "code_scanning": {},
            "infrastructure_scanning": {},
            "patch_management": {},
            "remediation_plan": {},
            "risk_assessment": {}
        }
        
        try:
            # 1. Scan dependencies
            logger.info("Scanning dependencies...")
            assessment_result["dependency_scanning"] = await self.scan_dependencies()
            
            # 2. Scan containers
            logger.info("Scanning containers...")
            assessment_result["container_scanning"] = await self.scan_containers()
            
            # 3. Scan source code
            logger.info("Scanning source code...")
            assessment_result["code_scanning"] = await self.scan_source_code()
            
            # 4. Scan infrastructure
            logger.info("Scanning infrastructure...")
            assessment_result["infrastructure_scanning"] = await self.scan_infrastructure()
            
            # 5. Setup patch management
            logger.info("Setting up patch management...")
            assessment_result["patch_management"] = await self.setup_patch_management()
            
            # 6. Create remediation plan
            logger.info("Creating remediation plan...")
            assessment_result["remediation_plan"] = await self.create_remediation_plan(
                assessment_result
            )
            
            # 7. Perform risk assessment
            logger.info("Performing risk assessment...")
            assessment_result["risk_assessment"] = await self.perform_risk_assessment(
                assessment_result
            )
            
            # 8. Setup continuous monitoring
            logger.info("Setting up continuous monitoring...")
            assessment_result["monitoring"] = await self.setup_continuous_monitoring()
            
            # 9. Generate security report
            await self.generate_security_report(assessment_result)
            
        except Exception as e:
            logger.error(f"Vulnerability assessment failed: {e}")
            assessment_result["error"] = str(e)
            
        return assessment_result
    
    async def scan_dependencies(self) -> Dict[str, Any]:
        """Scan project dependencies for vulnerabilities"""
        scan_results = {
            "python": await self.scan_python_dependencies(),
            "javascript": await self.scan_javascript_dependencies(),
            "docker": await self.scan_docker_dependencies()
        }
        
        total_vulnerabilities = sum(
            result.get("vulnerabilities_found", 0) 
            for result in scan_results.values()
        )
        
        critical_count = sum(
            result.get("critical", 0) 
            for result in scan_results.values()
        )
        
        return {
            "scan_results": scan_results,
            "total_vulnerabilities": total_vulnerabilities,
            "critical_vulnerabilities": critical_count,
            "scan_timestamp": datetime.now().isoformat()
        }
    
    async def scan_python_dependencies(self) -> Dict[str, Any]:
        """Scan Python dependencies using Safety"""
        try:
            # Check for requirements files
            requirements_files = [
                "backend/requirements.txt",
                "ml-pipeline/requirements.txt"
            ]
            
            vulnerabilities = []
            
            for req_file in requirements_files:
                if os.path.exists(req_file):
                    # Run safety check
                    cmd = ["safety", "check", "--json", "-r", req_file]
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    if result.returncode != 0 and result.stdout:
                        try:
                            safety_output = json.loads(result.stdout)
                            for vuln in safety_output:
                                vulnerabilities.append(Vulnerability(
                                    id=f"python-{vuln.get('vulnerability_id', 'unknown')}",
                                    type=VulnerabilityType.DEPENDENCY,
                                    severity=self._map_severity(vuln.get('severity', 'unknown')),
                                    title=vuln.get('package_name', 'Unknown package'),
                                    description=vuln.get('description', ''),
                                    affected_component=f"{vuln.get('package_name')}=={vuln.get('analyzed_version')}",
                                    cve_id=vuln.get('cve'),
                                    patch_available=True,
                                    patch_version=vuln.get('safe_version'),
                                    remediation=f"Update to {vuln.get('safe_version')}"
                                ))
                        except json.JSONDecodeError:
                            logger.warning(f"Failed to parse safety output for {req_file}")
            
            # Also run pip-audit for additional checks
            audit_cmd = ["pip-audit", "--format", "json"]
            audit_result = subprocess.run(audit_cmd, capture_output=True, text=True)
            
            if audit_result.returncode == 0 and audit_result.stdout:
                try:
                    audit_output = json.loads(audit_result.stdout)
                    for vuln in audit_output.get("vulnerabilities", []):
                        vulnerabilities.append(Vulnerability(
                            id=f"pip-audit-{vuln.get('id', 'unknown')}",
                            type=VulnerabilityType.DEPENDENCY,
                            severity=self._map_severity(vuln.get('fix_versions', [])),
                            title=vuln.get('name', 'Unknown'),
                            description=vuln.get('description', ''),
                            affected_component=vuln.get('name'),
                            cve_id=vuln.get('aliases', [None])[0] if vuln.get('aliases') else None,
                            patch_available=bool(vuln.get('fix_versions')),
                            patch_version=vuln.get('fix_versions', [None])[0]
                        ))
                except json.JSONDecodeError:
                    logger.warning("Failed to parse pip-audit output")
            
            severity_counts = self._count_by_severity(vulnerabilities)
            
            return {
                "vulnerabilities_found": len(vulnerabilities),
                "vulnerabilities": [self._vuln_to_dict(v) for v in vulnerabilities[:10]],
                **severity_counts
            }
            
        except Exception as e:
            logger.error(f"Python dependency scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_javascript_dependencies(self) -> Dict[str, Any]:
        """Scan JavaScript dependencies using npm audit"""
        try:
            vulnerabilities = []
            
            # Check frontend dependencies
            if os.path.exists("frontend/package.json"):
                os.chdir("frontend")
                
                # Run npm audit
                cmd = ["npm", "audit", "--json"]
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.stdout:
                    try:
                        audit_output = json.loads(result.stdout)
                        advisories = audit_output.get("advisories", {})
                        
                        for advisory_id, advisory in advisories.items():
                            vulnerabilities.append(Vulnerability(
                                id=f"npm-{advisory_id}",
                                type=VulnerabilityType.DEPENDENCY,
                                severity=self._map_npm_severity(advisory.get("severity")),
                                title=advisory.get("title", "Unknown"),
                                description=advisory.get("overview", ""),
                                affected_component=advisory.get("module_name"),
                                cve_id=advisory.get("cves", [None])[0] if advisory.get("cves") else None,
                                cvss_score=advisory.get("cvss", {}).get("score"),
                                patch_available=bool(advisory.get("patched_versions")),
                                patch_version=advisory.get("patched_versions"),
                                remediation=advisory.get("recommendation")
                            ))
                    except json.JSONDecodeError:
                        logger.warning("Failed to parse npm audit output")
                
                os.chdir("..")
            
            severity_counts = self._count_by_severity(vulnerabilities)
            
            return {
                "vulnerabilities_found": len(vulnerabilities),
                "vulnerabilities": [self._vuln_to_dict(v) for v in vulnerabilities[:10]],
                **severity_counts
            }
            
        except Exception as e:
            logger.error(f"JavaScript dependency scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_docker_dependencies(self) -> Dict[str, Any]:
        """Scan Docker base images for vulnerabilities"""
        try:
            vulnerabilities = []
            
            # Find Dockerfiles
            dockerfiles = list(Path(".").rglob("Dockerfile*"))
            
            for dockerfile in dockerfiles:
                # Extract base image
                with open(dockerfile, 'r') as f:
                    for line in f:
                        if line.startswith("FROM "):
                            base_image = line.split()[1]
                            
                            # Scan with Trivy
                            vuln_list = await self.scan_with_trivy(base_image)
                            vulnerabilities.extend(vuln_list)
                            break
            
            severity_counts = self._count_by_severity(vulnerabilities)
            
            return {
                "dockerfiles_scanned": len(dockerfiles),
                "vulnerabilities_found": len(vulnerabilities),
                "vulnerabilities": [self._vuln_to_dict(v) for v in vulnerabilities[:10]],
                **severity_counts
            }
            
        except Exception as e:
            logger.error(f"Docker dependency scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_containers(self) -> Dict[str, Any]:
        """Scan running containers for vulnerabilities"""
        try:
            if not self.docker_client:
                return {"error": "Docker not available"}
            
            containers = self.docker_client.containers.list()
            scan_results = []
            total_vulnerabilities = []
            
            for container in containers:
                # Scan container with Trivy
                vuln_list = await self.scan_container_with_trivy(container.id)
                
                scan_results.append({
                    "container": container.name,
                    "image": container.image.tags[0] if container.image.tags else "unknown",
                    "vulnerabilities": len(vuln_list),
                    "critical": sum(1 for v in vuln_list if v.severity == SeverityLevel.CRITICAL)
                })
                
                total_vulnerabilities.extend(vuln_list)
            
            severity_counts = self._count_by_severity(total_vulnerabilities)
            
            return {
                "containers_scanned": len(containers),
                "scan_results": scan_results,
                "total_vulnerabilities": len(total_vulnerabilities),
                **severity_counts
            }
            
        except Exception as e:
            logger.error(f"Container scanning failed: {e}")
            return {"error": str(e)}
    
    async def scan_with_trivy(self, image: str) -> List[Vulnerability]:
        """Scan image with Trivy"""
        vulnerabilities = []
        
        try:
            cmd = ["trivy", "image", "--format", "json", "--quiet", image]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout:
                trivy_output = json.loads(result.stdout)
                
                for target in trivy_output.get("Results", []):
                    for vuln in target.get("Vulnerabilities", []):
                        vulnerabilities.append(Vulnerability(
                            id=f"trivy-{vuln.get('VulnerabilityID', 'unknown')}",
                            type=VulnerabilityType.CONTAINER,
                            severity=self._map_trivy_severity(vuln.get("Severity")),
                            title=vuln.get("Title", vuln.get("VulnerabilityID", "Unknown")),
                            description=vuln.get("Description", ""),
                            affected_component=f"{vuln.get('PkgName')}:{vuln.get('InstalledVersion')}",
                            cve_id=vuln.get("VulnerabilityID"),
                            cvss_score=self._extract_cvss_score(vuln.get("CVSS")),
                            patch_available=bool(vuln.get("FixedVersion")),
                            patch_version=vuln.get("FixedVersion"),
                            references=vuln.get("References", [])
                        ))
        except Exception as e:
            logger.warning(f"Trivy scan failed for {image}: {e}")
        
        return vulnerabilities
    
    async def scan_container_with_trivy(self, container_id: str) -> List[Vulnerability]:
        """Scan running container with Trivy"""
        vulnerabilities = []
        
        try:
            # Export container filesystem
            temp_tar = f"/tmp/container_{container_id[:12]}.tar"
            
            container = self.docker_client.containers.get(container_id)
            with open(temp_tar, 'wb') as f:
                for chunk in container.export():
                    f.write(chunk)
            
            # Scan with Trivy
            cmd = ["trivy", "rootfs", "--format", "json", "--quiet", temp_tar]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout:
                trivy_output = json.loads(result.stdout)
                
                for target in trivy_output.get("Results", []):
                    for vuln in target.get("Vulnerabilities", []):
                        vulnerabilities.append(Vulnerability(
                            id=f"container-{vuln.get('VulnerabilityID', 'unknown')}",
                            type=VulnerabilityType.CONTAINER,
                            severity=self._map_trivy_severity(vuln.get("Severity")),
                            title=vuln.get("Title", "Unknown"),
                            description=vuln.get("Description", ""),
                            affected_component=f"{vuln.get('PkgName')}:{vuln.get('InstalledVersion')}",
                            cve_id=vuln.get("VulnerabilityID"),
                            patch_available=bool(vuln.get("FixedVersion")),
                            patch_version=vuln.get("FixedVersion")
                        ))
            
            # Clean up
            os.remove(temp_tar)
            
        except Exception as e:
            logger.warning(f"Container scan failed for {container_id}: {e}")
        
        return vulnerabilities
    
    async def scan_source_code(self) -> Dict[str, Any]:
        """Scan source code for security vulnerabilities"""
        scan_results = {
            "python_code": await self.scan_python_code(),
            "javascript_code": await self.scan_javascript_code(),
            "secrets": await self.scan_for_secrets(),
            "sast": await self.run_sast_scan()
        }
        
        total_issues = sum(
            result.get("issues_found", 0) 
            for result in scan_results.values()
        )
        
        return {
            "scan_results": scan_results,
            "total_issues": total_issues,
            "scan_timestamp": datetime.now().isoformat()
        }
    
    async def scan_python_code(self) -> Dict[str, Any]:
        """Scan Python code with Bandit"""
        try:
            cmd = ["bandit", "-r", "backend/", "-f", "json", "-ll"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            issues = []
            if result.stdout:
                try:
                    bandit_output = json.loads(result.stdout)
                    for issue in bandit_output.get("results", []):
                        issues.append({
                            "severity": issue.get("issue_severity"),
                            "confidence": issue.get("issue_confidence"),
                            "cwe": issue.get("issue_cwe", {}).get("id"),
                            "text": issue.get("issue_text"),
                            "file": issue.get("filename"),
                            "line": issue.get("line_number")
                        })
                except json.JSONDecodeError:
                    logger.warning("Failed to parse Bandit output")
            
            return {
                "tool": "bandit",
                "issues_found": len(issues),
                "issues": issues[:10],  # Top 10 issues
                "high_severity": sum(1 for i in issues if i.get("severity") == "HIGH"),
                "medium_severity": sum(1 for i in issues if i.get("severity") == "MEDIUM")
            }
            
        except Exception as e:
            logger.error(f"Python code scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_javascript_code(self) -> Dict[str, Any]:
        """Scan JavaScript code with ESLint security plugin"""
        try:
            os.chdir("frontend")
            
            cmd = ["npx", "eslint", "src/", "--ext", ".js,.jsx,.ts,.tsx", "--format", "json"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            issues = []
            if result.stdout:
                try:
                    eslint_output = json.loads(result.stdout)
                    for file_result in eslint_output:
                        for message in file_result.get("messages", []):
                            if "security" in message.get("ruleId", "").lower():
                                issues.append({
                                    "rule": message.get("ruleId"),
                                    "severity": message.get("severity"),
                                    "message": message.get("message"),
                                    "file": file_result.get("filePath"),
                                    "line": message.get("line")
                                })
                except json.JSONDecodeError:
                    logger.warning("Failed to parse ESLint output")
            
            os.chdir("..")
            
            return {
                "tool": "eslint-security",
                "issues_found": len(issues),
                "issues": issues[:10]
            }
            
        except Exception as e:
            logger.error(f"JavaScript code scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_for_secrets(self) -> Dict[str, Any]:
        """Scan for hardcoded secrets in code"""
        try:
            # Use truffleHog or git-secrets
            cmd = ["trufflehog", "filesystem", ".", "--json", "--only-verified"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            secrets_found = []
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        try:
                            secret = json.loads(line)
                            secrets_found.append({
                                "type": secret.get("detectorName"),
                                "file": secret.get("sourceMetadata", {}).get("data", {}).get("filesystem", {}).get("file"),
                                "verified": secret.get("verified"),
                                "redacted": secret.get("redacted")
                            })
                        except json.JSONDecodeError:
                            continue
            
            return {
                "tool": "trufflehog",
                "secrets_found": len(secrets_found),
                "secrets": secrets_found[:5]  # Limit exposure
            }
            
        except Exception as e:
            logger.error(f"Secret scanning failed: {e}")
            return {"error": str(e)}
    
    async def run_sast_scan(self) -> Dict[str, Any]:
        """Run Static Application Security Testing with Semgrep"""
        try:
            cmd = ["semgrep", "--config=auto", "--json", "backend/", "frontend/"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            findings = []
            if result.stdout:
                try:
                    semgrep_output = json.loads(result.stdout)
                    for finding in semgrep_output.get("results", []):
                        findings.append({
                            "check_id": finding.get("check_id"),
                            "severity": finding.get("extra", {}).get("severity"),
                            "message": finding.get("extra", {}).get("message"),
                            "file": finding.get("path"),
                            "line": finding.get("start", {}).get("line"),
                            "owasp": finding.get("extra", {}).get("metadata", {}).get("owasp")
                        })
                except json.JSONDecodeError:
                    logger.warning("Failed to parse Semgrep output")
            
            return {
                "tool": "semgrep",
                "findings": len(findings),
                "high_severity": sum(1 for f in findings if f.get("severity") == "ERROR"),
                "findings_sample": findings[:10]
            }
            
        except Exception as e:
            logger.error(f"SAST scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_infrastructure(self) -> Dict[str, Any]:
        """Scan infrastructure configuration"""
        scan_results = {
            "kubernetes": await self.scan_kubernetes_config(),
            "docker_compose": await self.scan_docker_compose(),
            "terraform": await self.scan_terraform_config(),
            "network": await self.scan_network_security()
        }
        
        return scan_results
    
    async def scan_kubernetes_config(self) -> Dict[str, Any]:
        """Scan Kubernetes configurations"""
        try:
            # Use kubesec or polaris
            k8s_files = list(Path("infrastructure/kubernetes").rglob("*.yaml"))
            
            issues = []
            for k8s_file in k8s_files:
                cmd = ["kubesec", "scan", str(k8s_file)]
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.stdout:
                    try:
                        kubesec_output = json.loads(result.stdout)
                        for item in kubesec_output:
                            score = item.get("score", 0)
                            if score < 0:
                                issues.append({
                                    "file": str(k8s_file),
                                    "score": score,
                                    "critical": item.get("scoring", {}).get("critical", []),
                                    "warning": item.get("scoring", {}).get("warning", [])
                                })
                    except json.JSONDecodeError:
                        continue
            
            return {
                "files_scanned": len(k8s_files),
                "issues_found": len(issues),
                "issues": issues
            }
            
        except Exception as e:
            logger.error(f"Kubernetes scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_docker_compose(self) -> Dict[str, Any]:
        """Scan Docker Compose configurations"""
        compose_files = list(Path(".").glob("docker-compose*.yml"))
        
        issues = []
        for compose_file in compose_files:
            with open(compose_file, 'r') as f:
                compose_config = yaml.safe_load(f)
                
                # Check for security issues
                for service_name, service_config in compose_config.get("services", {}).items():
                    # Check for privileged containers
                    if service_config.get("privileged"):
                        issues.append({
                            "service": service_name,
                            "issue": "Container running in privileged mode",
                            "severity": "high"
                        })
                    
                    # Check for root user
                    if not service_config.get("user"):
                        issues.append({
                            "service": service_name,
                            "issue": "Container running as root",
                            "severity": "medium"
                        })
                    
                    # Check for exposed ports
                    ports = service_config.get("ports", [])
                    for port in ports:
                        if "0.0.0.0:" in str(port):
                            issues.append({
                                "service": service_name,
                                "issue": f"Port {port} exposed to all interfaces",
                                "severity": "medium"
                            })
        
        return {
            "files_scanned": len(compose_files),
            "issues_found": len(issues),
            "issues": issues
        }
    
    async def scan_terraform_config(self) -> Dict[str, Any]:
        """Scan Terraform configurations"""
        try:
            # Use tfsec or checkov
            cmd = ["tfsec", ".", "--format", "json"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            issues = []
            if result.stdout:
                try:
                    tfsec_output = json.loads(result.stdout)
                    for finding in tfsec_output.get("results", []):
                        issues.append({
                            "rule_id": finding.get("rule_id"),
                            "severity": finding.get("severity"),
                            "description": finding.get("description"),
                            "resource": finding.get("resource"),
                            "location": finding.get("location")
                        })
                except json.JSONDecodeError:
                    logger.warning("Failed to parse tfsec output")
            
            return {
                "tool": "tfsec",
                "issues_found": len(issues),
                "issues": issues
            }
            
        except Exception as e:
            logger.error(f"Terraform scan failed: {e}")
            return {"error": str(e)}
    
    async def scan_network_security(self) -> Dict[str, Any]:
        """Scan network security configuration"""
        network_issues = []
        
        # Check for open ports
        open_ports = await self.check_open_ports()
        if open_ports:
            network_issues.append({
                "issue": "Open ports detected",
                "ports": open_ports,
                "severity": "medium"
            })
        
        # Check SSL/TLS configuration
        ssl_issues = await self.check_ssl_configuration()
        network_issues.extend(ssl_issues)
        
        return {
            "issues_found": len(network_issues),
            "issues": network_issues
        }
    
    async def check_open_ports(self) -> List[int]:
        """Check for open ports"""
        open_ports = []
        
        try:
            # Use netstat or ss
            cmd = ["netstat", "-tuln"]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.stdout:
                lines = result.stdout.strip().split('\n')
                for line in lines[2:]:  # Skip headers
                    parts = line.split()
                    if len(parts) >= 4:
                        addr = parts[3]
                        if "0.0.0.0:" in addr or ":::" in addr:
                            port = int(addr.split(':')[-1])
                            open_ports.append(port)
        except Exception as e:
            logger.warning(f"Port scan failed: {e}")
        
        return open_ports
    
    async def check_ssl_configuration(self) -> List[Dict[str, Any]]:
        """Check SSL/TLS configuration"""
        ssl_issues = []
        
        # Check certificate expiry
        # Check cipher suites
        # Check protocol versions
        
        return ssl_issues
    
    async def setup_patch_management(self) -> Dict[str, Any]:
        """Setup automated patch management"""
        try:
            # Create patch management database
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS patches (
                    id SERIAL PRIMARY KEY,
                    patch_id VARCHAR(255) UNIQUE NOT NULL,
                    vulnerability_id VARCHAR(255) NOT NULL,
                    component VARCHAR(255) NOT NULL,
                    current_version VARCHAR(100),
                    patch_version VARCHAR(100) NOT NULL,
                    status VARCHAR(50) DEFAULT 'available',
                    test_status VARCHAR(50),
                    applied_at TIMESTAMP,
                    rollback_available BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS patch_schedule (
                    id SERIAL PRIMARY KEY,
                    patch_id VARCHAR(255) NOT NULL,
                    scheduled_for TIMESTAMP NOT NULL,
                    maintenance_window VARCHAR(50),
                    approved_by VARCHAR(255),
                    approval_date TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.commit()
            cursor.close()
            conn.close()
            
            # Setup automated patching
            patching_config = {
                "auto_patch_enabled": True,
                "patch_window": "Sunday 02:00-06:00 UTC",
                "auto_approve_low": True,
                "auto_approve_medium": False,
                "auto_approve_high": False,
                "auto_approve_critical": False,
                "test_before_apply": True,
                "rollback_on_failure": True,
                "notification_channels": ["email", "slack"]
            }
            
            # Generate patch automation script
            script = self.generate_patch_automation_script()
            
            script_path = Path("infrastructure/security/auto_patch.sh")
            script_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(script_path, 'w') as f:
                f.write(script)
            
            os.chmod(script_path, 0o700)
            
            return {
                "status": "configured",
                "config": patching_config,
                "automation_script": script_path.as_posix(),
                "tables_created": 2
            }
            
        except Exception as e:
            logger.error(f"Failed to setup patch management: {e}")
            return {"error": str(e)}
    
    def generate_patch_automation_script(self) -> str:
        """Generate automated patching script"""
        script = """#!/bin/bash
# Automated Patch Management Script

set -e

LOG_FILE="/var/log/ytempire/patching.log"
BACKUP_DIR="/var/backups/pre-patch"

# Function to log messages
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
}

# Function to create backup
create_backup() {
    log "Creating pre-patch backup..."
    mkdir -p "$BACKUP_DIR"
    
    # Backup database
    pg_dump -h localhost -U postgres ytempire > "$BACKUP_DIR/database_$(date +%Y%m%d).sql"
    
    # Backup application
    tar -czf "$BACKUP_DIR/application_$(date +%Y%m%d).tar.gz" /app
    
    log "Backup completed"
}

# Function to test patches
test_patches() {
    log "Testing patches in staging environment..."
    
    # Run tests
    cd /app
    python -m pytest tests/
    
    if [ $? -eq 0 ]; then
        log "Patch testing successful"
        return 0
    else
        log "Patch testing failed"
        return 1
    fi
}

# Function to apply system patches
apply_system_patches() {
    log "Applying system patches..."
    
    # Update package lists
    apt-get update
    
    # Apply security updates only
    apt-get upgrade -y --security
    
    log "System patches applied"
}

# Function to apply Python patches
apply_python_patches() {
    log "Applying Python dependency patches..."
    
    cd /app/backend
    source venv/bin/activate
    
    # Update vulnerable packages
    pip install --upgrade $(pip list --outdated --format=json | jq -r '.[].name')
    
    # Run safety check
    safety check
    
    deactivate
    log "Python patches applied"
}

# Function to apply Node.js patches
apply_nodejs_patches() {
    log "Applying Node.js dependency patches..."
    
    cd /app/frontend
    
    # Run npm audit fix
    npm audit fix --force
    
    # Rebuild
    npm run build
    
    log "Node.js patches applied"
}

# Function to restart services
restart_services() {
    log "Restarting services..."
    
    systemctl restart ytempire-backend
    systemctl restart ytempire-celery
    systemctl restart nginx
    
    log "Services restarted"
}

# Function to verify patch application
verify_patches() {
    log "Verifying patch application..."
    
    # Check service health
    curl -f http://localhost:8000/health || return 1
    
    # Run security scan
    trivy fs /app --quiet --severity HIGH,CRITICAL
    
    log "Patch verification completed"
}

# Main execution
main() {
    log "Starting automated patching process"
    
    # Create backup
    create_backup
    
    # Apply patches
    apply_system_patches
    apply_python_patches
    apply_nodejs_patches
    
    # Test patches
    if test_patches; then
        # Restart services
        restart_services
        
        # Verify
        if verify_patches; then
            log "Patching completed successfully"
            exit 0
        else
            log "Patch verification failed, rolling back..."
            # Rollback logic here
            exit 1
        fi
    else
        log "Patch testing failed, aborting"
        exit 1
    fi
}

# Run main function
main
"""
        return script
    
    async def create_remediation_plan(self, assessment: Dict[str, Any]) -> Dict[str, Any]:
        """Create remediation plan based on assessment"""
        all_vulnerabilities = []
        
        # Collect all vulnerabilities
        for category in ["dependency_scanning", "container_scanning", "code_scanning"]:
            if category in assessment:
                scan_data = assessment[category]
                if isinstance(scan_data, dict) and "scan_results" in scan_data:
                    for result in scan_data["scan_results"].values():
                        if isinstance(result, dict) and "vulnerabilities" in result:
                            all_vulnerabilities.extend(result.get("vulnerabilities", []))
        
        # Prioritize vulnerabilities
        critical_vulns = [v for v in all_vulnerabilities if self._get_vuln_severity(v) == "critical"]
        high_vulns = [v for v in all_vulnerabilities if self._get_vuln_severity(v) == "high"]
        
        remediation_plan = {
            "immediate_actions": [],
            "short_term": [],
            "medium_term": [],
            "long_term": []
        }
        
        # Immediate actions (critical vulnerabilities)
        for vuln in critical_vulns[:10]:
            remediation_plan["immediate_actions"].append({
                "vulnerability": self._get_vuln_id(vuln),
                "severity": "critical",
                "component": self._get_vuln_component(vuln),
                "action": f"Update to {self._get_patch_version(vuln)}" if self._has_patch(vuln) else "Apply workaround",
                "timeline": "Within 24 hours"
            })
        
        # Short-term actions (high vulnerabilities)
        for vuln in high_vulns[:20]:
            remediation_plan["short_term"].append({
                "vulnerability": self._get_vuln_id(vuln),
                "severity": "high",
                "component": self._get_vuln_component(vuln),
                "action": f"Update to {self._get_patch_version(vuln)}" if self._has_patch(vuln) else "Mitigate risk",
                "timeline": "Within 1 week"
            })
        
        # Add general recommendations
        remediation_plan["recommendations"] = [
            "Enable automated security updates for OS packages",
            "Implement dependency update automation with Dependabot",
            "Schedule regular vulnerability scans (weekly)",
            "Establish patch management SLA",
            "Create security incident response team"
        ]
        
        return remediation_plan
    
    async def perform_risk_assessment(self, assessment: Dict[str, Any]) -> Dict[str, Any]:
        """Perform risk assessment based on vulnerabilities"""
        risk_scores = {
            "overall": 0,
            "dependencies": 0,
            "containers": 0,
            "code": 0,
            "infrastructure": 0
        }
        
        # Calculate risk scores
        if "dependency_scanning" in assessment:
            dep_scan = assessment["dependency_scanning"]
            critical = dep_scan.get("critical_vulnerabilities", 0)
            total = dep_scan.get("total_vulnerabilities", 0)
            risk_scores["dependencies"] = min(100, (critical * 20) + (total * 2))
        
        if "container_scanning" in assessment:
            cont_scan = assessment["container_scanning"]
            critical = cont_scan.get("critical", 0)
            high = cont_scan.get("high", 0)
            risk_scores["containers"] = min(100, (critical * 25) + (high * 10))
        
        if "code_scanning" in assessment:
            code_scan = assessment["code_scanning"]
            issues = code_scan.get("total_issues", 0)
            risk_scores["code"] = min(100, issues * 5)
        
        # Calculate overall risk
        risk_scores["overall"] = sum(risk_scores.values()) / len(risk_scores)
        
        # Determine risk level
        if risk_scores["overall"] >= 75:
            risk_level = "CRITICAL"
        elif risk_scores["overall"] >= 50:
            risk_level = "HIGH"
        elif risk_scores["overall"] >= 25:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"
        
        return {
            "risk_scores": risk_scores,
            "risk_level": risk_level,
            "recommendations": self._generate_risk_recommendations(risk_level),
            "compliance_impact": self._assess_compliance_impact(assessment)
        }
    
    def _generate_risk_recommendations(self, risk_level: str) -> List[str]:
        """Generate recommendations based on risk level"""
        recommendations = {
            "CRITICAL": [
                "Immediate action required - halt deployments",
                "Apply all critical patches within 24 hours",
                "Conduct emergency security review",
                "Notify security team and management"
            ],
            "HIGH": [
                "Prioritize security updates in next sprint",
                "Review and update security policies",
                "Increase monitoring and alerting",
                "Schedule security training for team"
            ],
            "MEDIUM": [
                "Plan security improvements for next quarter",
                "Review and update dependencies",
                "Implement additional security controls"
            ],
            "LOW": [
                "Maintain current security practices",
                "Continue regular security updates",
                "Monitor for new vulnerabilities"
            ]
        }
        
        return recommendations.get(risk_level, [])
    
    def _assess_compliance_impact(self, assessment: Dict[str, Any]) -> Dict[str, str]:
        """Assess impact on compliance"""
        return {
            "pci_dss": "May impact compliance if payment data is affected",
            "gdpr": "Personal data protection may be compromised",
            "hipaa": "Health data security requirements may not be met",
            "soc2": "Security controls may need review"
        }
    
    async def setup_continuous_monitoring(self) -> Dict[str, Any]:
        """Setup continuous vulnerability monitoring"""
        monitoring_config = {
            "scan_schedule": {
                "dependency_scan": "daily",
                "container_scan": "on_build",
                "code_scan": "on_commit",
                "infrastructure_scan": "weekly",
                "full_scan": "weekly"
            },
            "alert_thresholds": {
                "critical": 0,  # Alert immediately
                "high": 5,
                "medium": 20,
                "low": 50
            },
            "integrations": {
                "github": "security_advisories",
                "slack": "#security-alerts",
                "email": "security@ytempire.com",
                "jira": "auto_create_tickets"
            },
            "automation": {
                "auto_patch_low": True,
                "auto_create_pr": True,
                "auto_rollback": True
            }
        }
        
        # Setup GitHub Actions workflow
        workflow = self.generate_security_workflow()
        
        workflow_path = Path(".github/workflows/security-scan.yml")
        workflow_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(workflow_path, 'w') as f:
            f.write(workflow)
        
        return {
            "status": "configured",
            "config": monitoring_config,
            "workflow": workflow_path.as_posix()
        }
    
    def generate_security_workflow(self) -> str:
        """Generate GitHub Actions security workflow"""
        workflow = """name: Security Scanning

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight

jobs:
  dependency-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
  
  container-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: docker build -t ytempire:${{ github.sha }} .
      
      - name: Run Trivy container scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'ytempire:${{ github.sha }}'
          format: 'sarif'
          output: 'container-results.sarif'
      
      - name: Upload results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'container-results.sarif'
  
  code-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: auto
  
  secret-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: TruffleHog Secret Scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: HEAD
"""
        return workflow
    
    async def generate_security_report(self, assessment: Dict[str, Any]):
        """Generate comprehensive security report"""
        report_path = Path(f"security_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
        
        with open(report_path, 'w') as f:
            f.write("# YTEmpire Security Assessment Report\n\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Executive Summary
            f.write("## Executive Summary\n\n")
            
            if "risk_assessment" in assessment:
                risk = assessment["risk_assessment"]
                f.write(f"**Overall Risk Level**: {risk.get('risk_level', 'UNKNOWN')}\n")
                f.write(f"**Risk Score**: {risk.get('risk_scores', {}).get('overall', 0):.1f}/100\n\n")
            
            # Vulnerability Summary
            f.write("## Vulnerability Summary\n\n")
            
            total_vulns = 0
            critical_count = 0
            
            if "dependency_scanning" in assessment:
                dep = assessment["dependency_scanning"]
                total_vulns += dep.get("total_vulnerabilities", 0)
                critical_count += dep.get("critical_vulnerabilities", 0)
            
            f.write(f"- **Total Vulnerabilities**: {total_vulns}\n")
            f.write(f"- **Critical**: {critical_count}\n\n")
            
            # Detailed Findings
            f.write("## Detailed Findings\n\n")
            
            for category, data in assessment.items():
                if isinstance(data, dict) and "scan_results" in data:
                    f.write(f"### {category.replace('_', ' ').title()}\n\n")
                    
                    for scan_type, results in data["scan_results"].items():
                        if isinstance(results, dict):
                            f.write(f"**{scan_type}**:\n")
                            f.write(f"- Issues found: {results.get('vulnerabilities_found', results.get('issues_found', 0))}\n")
                            if "critical" in results:
                                f.write(f"- Critical: {results['critical']}\n")
                            if "high" in results:
                                f.write(f"- High: {results['high']}\n")
                            f.write("\n")
            
            # Remediation Plan
            if "remediation_plan" in assessment:
                f.write("## Remediation Plan\n\n")
                plan = assessment["remediation_plan"]
                
                if "immediate_actions" in plan and plan["immediate_actions"]:
                    f.write("### Immediate Actions (24 hours)\n\n")
                    for action in plan["immediate_actions"][:5]:
                        f.write(f"- {action.get('action', 'N/A')} for {action.get('component', 'N/A')}\n")
                    f.write("\n")
            
            # Recommendations
            f.write("## Recommendations\n\n")
            if "risk_assessment" in assessment:
                for rec in assessment["risk_assessment"].get("recommendations", []):
                    f.write(f"- {rec}\n")
            
            f.write("\n---\n")
            f.write("*This report is confidential and for internal use only*\n")
        
        logger.info(f"Security report generated: {report_path}")
    
    # Helper methods
    def _map_severity(self, severity: Any) -> SeverityLevel:
        """Map severity to enum"""
        if isinstance(severity, str):
            severity_lower = severity.lower()
            if "critical" in severity_lower:
                return SeverityLevel.CRITICAL
            elif "high" in severity_lower:
                return SeverityLevel.HIGH
            elif "medium" in severity_lower or "moderate" in severity_lower:
                return SeverityLevel.MEDIUM
            elif "low" in severity_lower:
                return SeverityLevel.LOW
        return SeverityLevel.INFO
    
    def _map_npm_severity(self, severity: str) -> SeverityLevel:
        """Map npm severity to enum"""
        mapping = {
            "critical": SeverityLevel.CRITICAL,
            "high": SeverityLevel.HIGH,
            "moderate": SeverityLevel.MEDIUM,
            "low": SeverityLevel.LOW,
            "info": SeverityLevel.INFO
        }
        return mapping.get(severity.lower(), SeverityLevel.INFO)
    
    def _map_trivy_severity(self, severity: str) -> SeverityLevel:
        """Map Trivy severity to enum"""
        mapping = {
            "CRITICAL": SeverityLevel.CRITICAL,
            "HIGH": SeverityLevel.HIGH,
            "MEDIUM": SeverityLevel.MEDIUM,
            "LOW": SeverityLevel.LOW,
            "UNKNOWN": SeverityLevel.INFO
        }
        return mapping.get(severity, SeverityLevel.INFO)
    
    def _extract_cvss_score(self, cvss_data: Any) -> Optional[float]:
        """Extract CVSS score from various formats"""
        if isinstance(cvss_data, dict):
            for key in ["score", "baseScore", "base_score"]:
                if key in cvss_data:
                    return float(cvss_data[key])
        return None
    
    def _count_by_severity(self, vulnerabilities: List[Vulnerability]) -> Dict[str, int]:
        """Count vulnerabilities by severity"""
        counts = {
            "critical": 0,
            "high": 0,
            "medium": 0,
            "low": 0,
            "info": 0
        }
        
        for vuln in vulnerabilities:
            counts[vuln.severity.value] += 1
        
        return counts
    
    def _vuln_to_dict(self, vuln: Vulnerability) -> Dict[str, Any]:
        """Convert vulnerability to dictionary"""
        return {
            "id": vuln.id,
            "type": vuln.type.value,
            "severity": vuln.severity.value,
            "title": vuln.title,
            "component": vuln.affected_component,
            "cve_id": vuln.cve_id,
            "patch_available": vuln.patch_available,
            "patch_version": vuln.patch_version
        }
    
    def _get_vuln_severity(self, vuln: Any) -> str:
        """Get vulnerability severity from various formats"""
        if isinstance(vuln, dict):
            return vuln.get("severity", "unknown")
        elif hasattr(vuln, "severity"):
            return vuln.severity.value if hasattr(vuln.severity, "value") else str(vuln.severity)
        return "unknown"
    
    def _get_vuln_id(self, vuln: Any) -> str:
        """Get vulnerability ID"""
        if isinstance(vuln, dict):
            return vuln.get("id", vuln.get("cve_id", "unknown"))
        elif hasattr(vuln, "id"):
            return vuln.id
        return "unknown"
    
    def _get_vuln_component(self, vuln: Any) -> str:
        """Get affected component"""
        if isinstance(vuln, dict):
            return vuln.get("component", vuln.get("affected_component", "unknown"))
        elif hasattr(vuln, "affected_component"):
            return vuln.affected_component
        return "unknown"
    
    def _has_patch(self, vuln: Any) -> bool:
        """Check if patch is available"""
        if isinstance(vuln, dict):
            return vuln.get("patch_available", False)
        elif hasattr(vuln, "patch_available"):
            return vuln.patch_available
        return False
    
    def _get_patch_version(self, vuln: Any) -> str:
        """Get patch version"""
        if isinstance(vuln, dict):
            return vuln.get("patch_version", "latest")
        elif hasattr(vuln, "patch_version"):
            return vuln.patch_version or "latest"
        return "latest"

async def main():
    """Main execution function"""
    logger.info("Starting Vulnerability Management")
    
    manager = VulnerabilityManager()
    results = await manager.perform_complete_vulnerability_assessment()
    
    print("\n" + "="*60)
    print("VULNERABILITY ASSESSMENT COMPLETE")
    print("="*60)
    
    # Dependency Scanning
    if "dependency_scanning" in results:
        dep = results["dependency_scanning"]
        print(f"\nDependency Scanning:")
        print(f"  Total vulnerabilities: {dep.get('total_vulnerabilities', 0)}")
        print(f"  Critical: {dep.get('critical_vulnerabilities', 0)}")
    
    # Container Scanning
    if "container_scanning" in results:
        cont = results["container_scanning"]
        print(f"\nContainer Scanning:")
        print(f"  Containers scanned: {cont.get('containers_scanned', 0)}")
        print(f"  Total vulnerabilities: {cont.get('total_vulnerabilities', 0)}")
    
    # Code Scanning
    if "code_scanning" in results:
        code = results["code_scanning"]
        print(f"\nCode Scanning:")
        print(f"  Total issues: {code.get('total_issues', 0)}")
    
    # Risk Assessment
    if "risk_assessment" in results:
        risk = results["risk_assessment"]
        print(f"\nRisk Assessment:")
        print(f"  Risk Level: {risk.get('risk_level', 'UNKNOWN')}")
        print(f"  Overall Score: {risk.get('risk_scores', {}).get('overall', 0):.1f}/100")
    
    # Patch Management
    if "patch_management" in results:
        patch = results["patch_management"]
        print(f"\nPatch Management:")
        print(f"  Status: {patch.get('status', 'unknown')}")
    
    print("\nSecurity report generated: security_report_*.md")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main())